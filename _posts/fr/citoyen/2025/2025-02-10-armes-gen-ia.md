---
title: Armes, IA génératives
slug: armes-gen-ia
translations:
    en: weapons-gen-ia
---

Lorsqu'un camp développe une arme, il est traditionnel que ses opposants cherchent à s'en emparer ou à concevoir une arme tout aussi destructrice afin d'établir un équilibre de dissuasion. Le monde numérique ne fait pas exception : pour chaque capacité de collecte de données ou d'attaque via des vecteurs de plus en plus sophistiqués présents dans un camp, l'autre camp élabore des contre-mesures et construit ses propres modes d'attaque.

L'émergence des IA génératives dans la sphère publique poursuit le travail d'astroturfing[^astroturfing] mené depuis des décennies, contribuant à éroder le concept même de vérité, tant en tant que réalité qu'en tant que possibilité. Si tout devient crédible, alors rien n'est véritablement vrai. Des tentatives de régulation émergent, mais elles avancent lentement et se révèlent complexes, car tous les acteurs ne s'accordent pas. Certains ont déjà sapé la vérité dans leur propre pays : détruire celle des autres n'est qu'une continuité de ce processus.

[^astroturfing]: une pratique de propagande trompeuse par laquelle des organisations ou des individus créent l'illusion d'un large soutien populaire à leur produit, service ou point de vue.

Ainsi, au lieu de cela, un marché se forme. On se félicite d'avoir inventé des outils si puissants qu'ils deviennent toujours plus destructeurs. On s'efforce de démanteler les faibles barrières réglementaires déjà en place ou sur le point d'être instaurées. On loue le multiplicateur économique de cette technologie, sans aucune connaissance de fond sur la question.

Et on retourne le vocabulaire, comme toujours : la régulation est une prison ; l'aide des États, un prérequis au succès (on aimerait que la même logique soit culturellement appliquée aux aides sociales) ; la modération est une forme de censure ; la liberté, c'est la domination par les puissants ; la compétition, y compris dans la victoire de contrats militaires, c'est la paix.

---

Une fois qu'on a dit ça, que faire ? Quelles questions aurais-je voulu voir émerger du sommet de l'IA (et je ne dis pas qu'elles n'y ont pas été abordées, juste qu'elles n'ont pas été médiatisées) ?

Je ne pense pas qu'on puisse imaginer un monde qui, aujourd'hui, se passerait d'IA générative. La technologie a tellement infusé dans les pratiques, en si peu de temps… ça me semble impossible. Mais on peut se demander, collectivement, ce qu'on veut comme IA.

Du point de vue écologique, d'abord, je pense que la Corporate Sustainability Report Directive (CSRD) de l'Union Européenne et plus globalement, la Science-Based Targets initiative (SBTi) vont dans le bon sens en créant une comptabilité non-financière des émissions de gaz à effet de serre (GES).

Ça ne peut marcher que si la régulation est maintenue, renforcée et publicisée dans le temps. Savoir qu'une entreprise comme [Microsoft dépasse de 29 % ses objectifs](https://microsoft.developpez.com/actu/357928/Les-emissions-de-Microsoft-augmentent-de-29-pourcent-en-raison-de-son-obsession-pour-l-IA-qui-engloutit-les-ressources-et-stimule-l-expansion-des-centres-de-donnees-a-forte-intensite-de-carbone/) est important. Si ce dépassement a des impacts sur le rapport de durabilité de leurs clients, alors seulement crée-t-on une situation de concurrence autour des indicateurs écologiques au bénéfice de la planète.

Mais la question dépasse très largement le sujet écologique : nous avons besoin d'entreprises qui discutent et mettent en place des cribles très précis sur les IA qu'elles utilisent, et les cas d'usage où elles les appliquent. Ces cribles doivent contenir :

- les cas d'usage spécifiques, et leurs critères de succès ;
- un travail d'enquêtes sur les modèles disponibles, leurs capacités et leurs biais ;
- des protocoles de tests avec des échantillons de cas d'usage et une évaluation du retour ;
- un cadre d'explicabilité permettant une transparence du processus de décision et lui-même audité indépendamment pour en valider le caractère légal et l'engagement de la responsabilité de l'organisation ;
- un mécanisme de surveillance continue, avec un plan de reprise d'activité si l'IA doit être débranchée.

Je suis convaincu que tous ces besoins créeront des emplois à l'avenir, du cabinet de conseil en choix d'IA à la structure spécialisée en surveillance continue, en passant par le cabinet d'audit indépendant, voire même spécialisé sur la tâche IA spécifique (on n'audite pas de la même manière une IA générative de traduction, de labellisation ou de discussion générale).

La vitesse à laquelle nous avancerons sur ces sujets dépendra de notre courage politique et de notre capacité à tenir tête aux intérêts économiques des grands acteurs de l'IA qui ne veulent pas vraiment de ce type de compétition-là.

À nous de les y forcer.
